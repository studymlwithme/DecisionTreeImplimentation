{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaSRbOv1t+7A5xMa5OpH3c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/studymlwithme/DecisionTreeImplimentation/blob/main/DecionTreesFromScratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J7SbgbdPLthF"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris, load_wine, load_diabetes\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from scipy import stats\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import r2_score\n",
        "from copy import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris_ds = load_iris()\n",
        "wine_ds = load_wine()\n",
        "diabetes_ds = load_diabetes(scaled=False)"
      ],
      "metadata": {
        "id": "I4vaKVtLLy3I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris_ds.data\n",
        "Y = iris_ds.target"
      ],
      "metadata": {
        "id": "U0hjPZ78L0Mf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class BTnode:\n",
        "  def __init__(self, c_o_d=None, split=None, parent=None, l_child=None, r_child=None, impurity_val=None, subset_indices=None, pred_val = None, feature=None):\n",
        "    self.c_o_d = c_o_d\n",
        "    self.feature = feature\n",
        "    self.split =  split\n",
        "    self.pred_val = pred_val\n",
        "    self.impurity_val = impurity_val\n",
        "    self.subset_indices = subset_indices\n",
        "    self.parent = parent\n",
        "    self.l_child = l_child\n",
        "    self.r_child = r_child\n",
        "\n",
        "class myDecisionTree:\n",
        "  def __init__(self, max_depth=20, max_leaf_nodes=20):\n",
        "    self.max_depth = max_depth\n",
        "    self.max_leaf_nodes = max_leaf_nodes\n",
        "    self.trained_dt = BTnode()\n",
        "\n",
        "  #This assumes all features have been converted to ints if they were previously categorical\n",
        "  def continuous_or_discrete(self, X, threshold_perc = .05, threshold_num = None):\n",
        "    if threshold_num == None:\n",
        "      # Use threshold Perc\n",
        "      unique_feat = np.unique(X)\n",
        "      num_sam = X.shape[0]\n",
        "      if len(unique_feat)/num_sam > threshold_perc:\n",
        "        return \"continuous\"\n",
        "      else:\n",
        "        return \"discrete\"\n",
        "    else:\n",
        "      # Use threshold Num\n",
        "      unique_feat = np.unique(X)\n",
        "      num_sam = X.shape[0]\n",
        "      if len(unique_feat) > threshold_num:\n",
        "        return \"continuous\", len(unique_feat)\n",
        "      else:\n",
        "        return \"discrete\"\n",
        "\n",
        "\n",
        "\n",
        "  def discrete_split(self, X, Y, measure):\n",
        "    if measure == 'MSE':\n",
        "      node_subset_len = X.shape[0]\n",
        "      #print(c_o_d)\n",
        "      best_split = None\n",
        "      best_mse = None\n",
        "      pred_val = None\n",
        "      d_len = X.shape[0]\n",
        "      for value in set(X):\n",
        "        l_node = np.take(Y, np.where(X==value))[0]\n",
        "        l_len = l_node.shape[0]\n",
        "        l_pred = value\n",
        "        #print(f'l_node: {l_node}, len: {l_len}')\n",
        "        l_mse = np.sum((l_pred - l_node)**2)/l_len\n",
        "        #print(l_pred - l_node, f\"val difference pred: {l_pred}, node: {l_node}, l_mse: {l_mse} difference: {(l_pred - l_node)**2} sum: {np.sum((l_pred - l_node)**2)}\")\n",
        "        r_node = np.take(Y, np.where(X!=value))[0]\n",
        "        r_len = r_node.shape[0]\n",
        "        r_pred = value\n",
        "        r_mse = np.sum((r_pred - r_node)**2)/r_len\n",
        "        total_mse = (l_len/d_len)*l_mse + (r_len/d_len)*r_mse\n",
        "        if best_mse == None:\n",
        "          best_mse = total_mse\n",
        "          pred_val = l_pred\n",
        "          best_split = value\n",
        "        elif best_mse > total_mse:\n",
        "          best_mse = total_mse\n",
        "          pred_val = l_pred\n",
        "          best_split = value\n",
        "      return best_mse, best_split\n",
        "    if measure == 'Gini':\n",
        "      node_subset_len = X.shape[0]\n",
        "      d_len = X.shape[0]\n",
        "      best_class_impurity_vals = None\n",
        "      best_split = None\n",
        "      #print(node_subset_len)\n",
        "      for value in set(X):\n",
        "        l_node = np.take(Y, np.where(X==value))[0]\n",
        "        l_len = l_node.shape[1]\n",
        "        ly_value_counts = np.unique(l_node, return_counts = True)\n",
        "        r_node = np.take(Y, np.where(X!=value))[0]\n",
        "        r_len = r_node.shape[1]\n",
        "        ry_value_counts = np.unique(r_node, return_counts = True)\n",
        "        r_curr_gin_impurity = 1\n",
        "        l_curr_gin_impurity = 1\n",
        "        temp_class_impurity_val = 0\n",
        "        for item in ry_value_counts[1]:\n",
        "          # its the number of each class we have within the split\n",
        "          r_curr_gin_impurity -= ((item/r_len)**2)\n",
        "          #temp_impurity_vals.append(([index]/node_subset_len)**2)\n",
        "        for item in ly_value_counts[1]:\n",
        "          # its the number of each class we have within the split\n",
        "          #print(f\"Item: {item} l_len: {l_len} node_subset_len: {node_subset_len} \")\n",
        "          l_curr_gin_impurity -= ((item/l_len)**2)\n",
        "        temp_class_impurity_val = (r_curr_gin_impurity*node_subset_len + l_curr_gin_impurity*node_subset_len)/d_len\n",
        "        if best_class_impurity_vals == None:\n",
        "          best_class_impurity_vals = temp_class_impurity_val\n",
        "          best_split = average_of_ixs\n",
        "        elif best_class_impurity_vals > temp_class_impurity_val:\n",
        "          best_class_impurity_vals = temp_class_impurity_val\n",
        "          best_split = average_of_ixs\n",
        "      return best_class_impurity_vals, best_split\n",
        "\n",
        "  def continuous_split(self, X, Y, measure):\n",
        "    if measure == 'MSE':\n",
        "      node_subset_len = X.shape[0]\n",
        "      #print(c_o_d)\n",
        "      best_split = None\n",
        "      best_mse = None\n",
        "      pred_val = None\n",
        "      sorted_indices = X.argsort()\n",
        "      X = X[sorted_indices]\n",
        "      Y = Y[sorted_indices]\n",
        "      d_len = X.shape[0]\n",
        "      for index in range(node_subset_len-1):\n",
        "        average_of_ixs = (X[index] + X[index+1])/2\n",
        "        l_node = np.take(Y, np.where(X<=average_of_ixs))[0]\n",
        "        l_len = l_node.shape[0]\n",
        "\n",
        "        l_pred = np.average(l_node)\n",
        "        #print(f'l_node: {l_node}, len: {l_len}')\n",
        "        l_mse = np.sum((l_pred - l_node)**2)/l_len\n",
        "        #print(l_pred - l_node, f\"val difference pred: {l_pred}, node: {l_node}, l_mse: {l_mse} difference: {(l_pred - l_node)**2} sum: {np.sum((l_pred - l_node)**2)}\")\n",
        "        r_node = np.take(Y, np.where(X>average_of_ixs))[0]\n",
        "        r_len = r_node.shape[0]\n",
        "        r_pred = np.average(r_node)\n",
        "        r_mse = np.sum((r_pred - r_node)**2)/r_len\n",
        "        total_mse = (l_len/d_len)*l_mse + (r_len/d_len)*r_mse\n",
        "        if best_mse == None:\n",
        "          best_mse = total_mse\n",
        "          pred_val = l_pred\n",
        "          best_split = average_of_ixs\n",
        "        elif best_mse > total_mse:\n",
        "          best_mse = total_mse\n",
        "          pred_val = l_pred\n",
        "          best_split = average_of_ixs\n",
        "        #print(best_mse, pred_val, best_split)\n",
        "      return best_mse, best_split\n",
        "    if measure == 'Gini':\n",
        "      node_subset_len = X.shape[0]\n",
        "      sorted_indices = X.argsort()\n",
        "      #print(sorted_indices, X)\n",
        "      X = X[sorted_indices]\n",
        "      Y = Y[sorted_indices]\n",
        "      d_len = X.shape[0]\n",
        "      best_class_impurity_vals = None\n",
        "      best_split = None\n",
        "      #print(node_subset_len)\n",
        "      for index in range(node_subset_len-1):\n",
        "        average_of_ixs = (X[index] + X[index+1])/2\n",
        "        l_node = np.take(Y, np.where(X<=average_of_ixs))\n",
        "        l_len = l_node.shape[1]\n",
        "        ly_value_counts = np.unique(l_node, return_counts = True)\n",
        "        r_node = np.take(Y, np.where(X>average_of_ixs))\n",
        "        r_len = r_node.shape[1]\n",
        "        ry_value_counts = np.unique(r_node, return_counts = True)\n",
        "        r_curr_gin_impurity = 1\n",
        "        l_curr_gin_impurity = 1\n",
        "        temp_class_impurity_val = 0\n",
        "        for item in ry_value_counts[1]:\n",
        "          # its the number of each class we have within the split\n",
        "          r_curr_gin_impurity -= ((item/r_len)**2)\n",
        "          #temp_impurity_vals.append(([index]/node_subset_len)**2)\n",
        "        for item in ly_value_counts[1]:\n",
        "          # its the number of each class we have within the split\n",
        "          #print(f\"Item: {item} l_len: {l_len} node_subset_len: {node_subset_len} \")\n",
        "          l_curr_gin_impurity -= ((item/l_len)**2)\n",
        "        temp_class_impurity_val = (r_curr_gin_impurity*node_subset_len + l_curr_gin_impurity*node_subset_len)/d_len\n",
        "        if best_class_impurity_vals == None:\n",
        "          best_class_impurity_vals = temp_class_impurity_val\n",
        "          best_split = average_of_ixs\n",
        "        elif best_class_impurity_vals > temp_class_impurity_val:\n",
        "          best_class_impurity_vals = temp_class_impurity_val\n",
        "          best_split = average_of_ixs\n",
        "      return best_class_impurity_vals, best_split\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    BT = BTnode()\n",
        "    y_c_o_d = self.continuous_or_discrete(Y)\n",
        "    self.trained_dt = self.find_best_split(X,Y, 0, BT, y_c_o_d)\n",
        "\n",
        "\n",
        "  def find_best_split(self, X, Y, depth, tree, y_c_o_d):\n",
        "    print(depth, \"<--- Depth\")\n",
        "    if depth < 5 and X.shape[0] > 2:\n",
        "      depth +=1\n",
        "    else:\n",
        "      return tree\n",
        "    # i believe my understanding of gini impurity and regression is incorrect in terms of when to use it. I believe that we use regression gini impurity AWLAYS based on the target class; what may change is how we split the data - as we may have continuous of discrete variables. But if our output is always classification then I am pretty sure we can always use gini impurity\n",
        "\n",
        "    best_class_impurity_vals = None\n",
        "    best_split = np.inf\n",
        "    best_c_o_d = None\n",
        "    best_feature = 0  #<--- setting as place holder to appease the program\n",
        "\n",
        "    static_X = copy(X)\n",
        "    for index, column in enumerate(X.T):\n",
        "      #print(column, \"THIS IS A COLUMN^>\")\n",
        "      c_o_d = self.continuous_or_discrete(X)\n",
        "      if c_o_d == \"continuous\":\n",
        "        if y_c_o_d == \"continuous\":\n",
        "          temp_class_impurity_vals, temp_split = self.continuous_split(column, Y, \"MSE\")\n",
        "          if best_class_impurity_vals == None:\n",
        "              best_feature = index\n",
        "              best_class_impurity_vals, best_split =  temp_class_impurity_vals, temp_split\n",
        "              best_c_o_d = c_o_d\n",
        "              #print(best_split)\n",
        "          elif best_class_impurity_vals > temp_class_impurity_vals:\n",
        "              best_feature = index\n",
        "              best_class_impurity_vals, best_split =  copy(temp_class_impurity_vals), copy(temp_split)\n",
        "              #print(best_class_impurity_vals, best_split)\n",
        "              best_c_o_d = c_o_d\n",
        "        else:\n",
        "          temp_class_impurity_vals, temp_split = self.continuous_split(column, Y, \"Gini\")\n",
        "          print(temp_class_impurity_vals)\n",
        "          if best_class_impurity_vals == None:\n",
        "              best_feature = index\n",
        "              best_class_impurity_vals, best_split =  temp_class_impurity_vals, temp_split\n",
        "              best_c_o_d = c_o_d\n",
        "              #print(best_split)\n",
        "          elif best_class_impurity_vals > temp_class_impurity_vals:\n",
        "              best_feature = index\n",
        "              best_class_impurity_vals, best_split =  copy(temp_class_impurity_vals), copy(temp_split)\n",
        "              #print(best_class_impurity_vals, best_split)\n",
        "              best_c_o_d = c_o_d\n",
        "      elif c_o_d == \"discrete\":\n",
        "        if y_c_o_d == \"continuous\":\n",
        "          temp_class_impurity_vals, temp_split = self.discrete_split(column, Y, \"MSE\")\n",
        "          if best_class_impurity_vals == None:\n",
        "              best_feature = index\n",
        "              best_class_impurity_vals, best_split =  temp_class_impurity_vals, temp_split\n",
        "              best_c_o_d = c_o_d\n",
        "              #print(best_split)\n",
        "          elif best_class_impurity_vals > temp_class_impurity_vals:\n",
        "              best_feature = index\n",
        "              best_class_impurity_vals, best_split =  copy(temp_class_impurity_vals), copy(temp_split)\n",
        "              #print(best_class_impurity_vals, best_split)\n",
        "              best_c_o_d = c_o_d\n",
        "        else:\n",
        "          temp_class_impurity_vals, temp_split = self.discrete_split(column, Y, \"Gini\")\n",
        "          print(temp_class_impurity_vals)\n",
        "          if best_class_impurity_vals == None:\n",
        "              best_feature = index\n",
        "              best_class_impurity_vals, best_split =  temp_class_impurity_vals, temp_split\n",
        "              best_c_o_d = c_o_d\n",
        "              #print(best_split)\n",
        "          elif best_class_impurity_vals > temp_class_impurity_vals:\n",
        "              best_feature = index\n",
        "              best_class_impurity_vals, best_split =  copy(temp_class_impurity_vals), copy(temp_split)\n",
        "              #print(best_class_impurity_vals, best_split)\n",
        "              best_c_o_d = c_o_d\n",
        "\n",
        "    print(\"BEST VALUES\", best_class_impurity_vals, best_split)\n",
        "    if c_o_d == 'continuous':\n",
        "      r_subset_Y = Y[X[:,best_feature]>best_split]\n",
        "      r_subset_X = X[X[:,best_feature]>best_split, :]\n",
        "      l_subset_Y = Y[X[:,best_feature]<=best_split]\n",
        "      l_subset_X = X[X[:,best_feature]<=best_split, :]\n",
        "    else:\n",
        "      r_subset_Y = Y[X[:,best_feature]!=best_split]\n",
        "      r_subset_X = X[X[:,best_feature]!=best_split, :]\n",
        "      l_subset_Y = Y[X[:,best_feature]==best_split]\n",
        "      l_subset_X = X[X[:,best_feature]==best_split, :]\n",
        "    if y_c_o_d == 'discrete':\n",
        "      unique, counts = np.unique(r_subset_Y, return_counts=True)\n",
        "      max_index = np.argmax(counts)\n",
        "      most_frequent = unique[max_index]\n",
        "      r_prediction = most_frequent\n",
        "      unique, counts = np.unique(l_subset_Y, return_counts=True)\n",
        "      max_index = np.argmax(counts)\n",
        "      most_frequent = unique[max_index]\n",
        "      l_prediction = most_frequent\n",
        "    else:\n",
        "      l_prediction = np.average(l_subset_Y)\n",
        "      r_prediction = np.average(r_subset_Y)\n",
        "\n",
        "    print(f'Predictions l_pred: {l_prediction} r_pred: {r_prediction}')\n",
        "    tree.c_o_d = best_c_o_d\n",
        "    tree.split = best_split\n",
        "    tree.impurity_val = best_class_impurity_vals\n",
        "    tree.feature = best_feature\n",
        "    #print(tree)\n",
        "    l_node = BTnode(None, None, tree, None, None, None, np.where(X[:,best_feature]<=best_split), pred_val = l_prediction)\n",
        "    r_node = BTnode(None, None, tree, None, None, None, np.where(X[:,best_feature]>best_split), pred_val = r_prediction)\n",
        "    r_node = self.find_best_split(r_subset_X, r_subset_Y, depth, r_node, y_c_o_d)\n",
        "    l_node = self.find_best_split(l_subset_X, l_subset_Y, depth, l_node, y_c_o_d)\n",
        "    tree.l_child = l_node\n",
        "    tree.r_child = r_node\n",
        "    return tree\n",
        "\n",
        "  def pred_val_from_tree(self, x, curr_node):\n",
        "    if curr_node.l_child == None and curr_node.r_child == None:\n",
        "      return curr_node.pred_val\n",
        "    if curr_node.c_o_d == 'continuous':\n",
        "      if x[curr_node.feature] > curr_node.split:\n",
        "        pred_val = self.pred_val_from_tree(x, curr_node.r_child)\n",
        "      elif x[curr_node.feature] <= curr_node.split:\n",
        "        pred_val = self.pred_val_from_tree(x, curr_node.l_child)\n",
        "    if curr_node.c_o_d == 'discrete':\n",
        "      if x[curr_node.feature] != curr_node.split:\n",
        "        pred_val = self.pred_val_from_tree(x, curr_node.r_child)\n",
        "      elif x[curr_node.feature] == curr_node.split:\n",
        "        pred_val = self.pred_val_from_tree(x, curr_node.l_child)\n",
        "    return pred_val\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    pred_vals = []\n",
        "    for row in X:\n",
        "      pred_vals.append(self.pred_val_from_tree(row, self.trained_dt))\n",
        "    return pred_vals\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uXbqKDptL1yn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, random_state=41)"
      ],
      "metadata": {
        "id": "3lhMGfZRNNac"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = myDecisionTree()\n",
        "bt = BTnode()\n",
        "gp = dt.fit(X_train, y_train)\n",
        "pred_vals = dt.predict(X_test)\n",
        "\n",
        "print(pred_vals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqYuwTmsNPdI",
        "outputId": "dbbf3410-4bfe-4502-deed-d33110aaf5a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 <--- Depth\n",
            "0.6567983531026371\n",
            "0.6609113563545745\n",
            "0.4996141975308643\n",
            "0.4996141975308643\n",
            "BEST VALUES 0.4996141975308643 1.9\n",
            "Predictions l_pred: 0 r_pred: 2\n",
            "1 <--- Depth\n",
            "0.48779296875\n",
            "0.49265381083562904\n",
            "0.20452408282524104\n",
            "0.15681641729528722\n",
            "BEST VALUES 0.15681641729528722 1.5\n",
            "Predictions l_pred: 1 r_pred: 2\n",
            "2 <--- Depth\n",
            "0.1022644265887509\n",
            "0.1049382716049383\n",
            "0.1022644265887509\n",
            "0.1022644265887509\n",
            "BEST VALUES 0.1022644265887509 5.65\n",
            "Predictions l_pred: 2 r_pred: 2\n",
            "3 <--- Depth\n",
            "0.1049382716049383\n",
            "0.10775510204081629\n",
            "0.1049382716049383\n",
            "0.1049382716049383\n",
            "BEST VALUES 0.1049382716049383 5.75\n",
            "Predictions l_pred: 2 r_pred: 2\n",
            "4 <--- Depth\n",
            "0.10775510204081629\n",
            "0.11072664359861584\n",
            "0.10775510204081629\n",
            "0.10775510204081629\n",
            "BEST VALUES 0.10775510204081629 7.7\n",
            "Predictions l_pred: 2 r_pred: 2\n",
            "5 <--- Depth\n",
            "5 <--- Depth\n",
            "4 <--- Depth\n",
            "3 <--- Depth\n",
            "2 <--- Depth\n",
            "0.05876951331496776\n",
            "0.05876951331496776\n",
            "0.0\n",
            "0.060546875\n",
            "BEST VALUES 0.0 4.9\n",
            "Predictions l_pred: 1 r_pred: 2\n",
            "3 <--- Depth\n",
            "3 <--- Depth\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "BEST VALUES 0.0 4.95\n",
            "Predictions l_pred: 1 r_pred: 1\n",
            "4 <--- Depth\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "BEST VALUES 0.0 5.05\n",
            "Predictions l_pred: 1 r_pred: 1\n",
            "5 <--- Depth\n",
            "5 <--- Depth\n",
            "4 <--- Depth\n",
            "1 <--- Depth\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "BEST VALUES 0.0 4.35\n",
            "Predictions l_pred: 0 r_pred: 0\n",
            "2 <--- Depth\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "BEST VALUES 0.0 4.4\n",
            "Predictions l_pred: 0 r_pred: 0\n",
            "3 <--- Depth\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "BEST VALUES 0.0 4.6\n",
            "Predictions l_pred: 0 r_pred: 0\n",
            "4 <--- Depth\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "BEST VALUES 0.0 4.75\n",
            "Predictions l_pred: 0 r_pred: 0\n",
            "5 <--- Depth\n",
            "5 <--- Depth\n",
            "4 <--- Depth\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "BEST VALUES 0.0 3.1500000000000004\n",
            "Predictions l_pred: 0 r_pred: 0\n",
            "5 <--- Depth\n",
            "5 <--- Depth\n",
            "3 <--- Depth\n",
            "2 <--- Depth\n",
            "[2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 0, 0, 1, 0, 2, 0, 2, 0, 0, 1, 2, 0, 0, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 2, 0, 2, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skDt_re = DecisionTreeRegressor(max_depth = 5)\n",
        "skDt_cl = DecisionTreeClassifier(max_depth = 5)"
      ],
      "metadata": {
        "id": "SLjSUqzpNQ2f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skDt_cl.fit(X_train, y_train)\n",
        "cl_skDt_pred = skDt_cl.predict(X_test)\n",
        "skDt_re.fit(X_train, y_train)\n",
        "re_skDt_pred = skDt_re.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "my_r2 = r2_score(y_test, pred_vals)\n",
        "my_ac = accuracy_score(y_test, pred_vals)\n",
        "cl__r2 = accuracy_score(y_test, cl_skDt_pred)\n",
        "re__r2 = r2_score(y_test, re_skDt_pred)\n",
        "\n",
        "print(my_r2, my_ac, cl__r2, re__r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvzEG56kNUo9",
        "outputId": "0a09a2ac-d597-4885-9cc6-d69777909163"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8682080924855491 0.9210526315789473 0.9210526315789473 0.8682080924855491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Feb6KX7ONWVL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}